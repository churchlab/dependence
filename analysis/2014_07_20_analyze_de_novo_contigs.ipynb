{
 "metadata": {
  "name": "",
  "signature": "sha256:8113ecf3cb698dd10d03a26e1f903f60311a4a933c50be1952074ee27749721e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import random\n",
      "import re\n",
      "import time\n",
      "\n",
      "from Bio import SeqIO\n",
      "from Bio.Blast import NCBIWWW\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "VELVET_DATA_DIR = os.path.join('data/velvet_assemblies/')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Create Master Spreadsheet\n",
      "\n",
      "Let's make a spreadsheet out of the assemblies so that we can more easily triage/compare."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def parse_contig_info(name):\n",
      "    \"\"\"Parses contig info from the name generated by velvet.\n",
      "    \"\"\"\n",
      "    m = re.match(r'(?P<id>.*)_length_(?P<length>[\\d]+)_cov_(?P<coverage>[\\d\\.]+)', name)\n",
      "    return {\n",
      "        'id': m.group('id'),\n",
      "        'length': int(m.group('length')),\n",
      "        'coverage': float(m.group('coverage'))\n",
      "    }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_dict_list = []\n",
      "CONTIG_SOURCE_FASTAS = os.path.join(VELVET_DATA_DIR, 'fasta')\n",
      "for filename in os.listdir(CONTIG_SOURCE_FASTAS):\n",
      "    parts = os.path.splitext(filename)\n",
      "    if len(parts) < 2 or parts[1] != '.fa':\n",
      "        continue\n",
      "    sample = parts[0]\n",
      "    full_path = os.path.join(CONTIG_SOURCE_FASTAS, filename)\n",
      "    with open(full_path) as fh:\n",
      "        records = SeqIO.parse(fh, 'fasta')\n",
      "        for r in records:\n",
      "            data_dict = {\n",
      "                'sample': sample,\n",
      "                'sequence': str(r.seq),\n",
      "                'note': '',\n",
      "                'flag': '',\n",
      "            }\n",
      "            data_dict.update(parse_contig_info(r.name))\n",
      "            data_dict['id'] = sample + '_' + data_dict['id']\n",
      "            data_dict_list.append(data_dict)\n",
      "contig_data_df = pd.DataFrame(data_dict_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 266
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sort the columns and write output to master csv."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sort_dataframe_columns(df, priority_columns):\n",
      "    \"\"\"Returns new DataFrame with priority columns first, then remaining columns.\n",
      "    \"\"\"\n",
      "    columns = list(df.columns)\n",
      "    reordered_columns = []\n",
      "    for col in priority_columns:\n",
      "        assert col in columns\n",
      "        columns.remove(col)\n",
      "        reordered_columns.append(col)\n",
      "    reordered_columns.extend(columns)\n",
      "    return df[reordered_columns]\n",
      "contig_data_df = sort_dataframe_columns(contig_data_df, ['id', 'sample', 'length', 'coverage', 'flag', 'note', 'sequence'])\n",
      "contig_data_df.sort(columns=['length', 'sample'], ascending=False).to_csv(\n",
      "        os.path.join(VELVET_DATA_DIR, 'contig_data_all_8_samples.csv'),\n",
      "        index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 199
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## BLAST all the sequences using NCBI."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, we kick off a bunch of requests in parallel (we modify Biopython NCBIWWW qblast function to just return the `rid` of the request).\n",
      "\n",
      "Then, we'll collect our results as they become ready."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### First step: Put jobs on queue"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_rows = len(contig_data_df)\n",
      "for idx, row in contig_data_df.iterrows():\n",
      "    contig_id = row['id']\n",
      "    if contig_id in contig_id_to_ncbi_rid:\n",
      "        continue\n",
      "    print 'Running %d of %d' % (idx + 1, num_rows)\n",
      "    rid = NCBIWWW.qblast('blastn', 'nr', row['sequence'])\n",
      "    contig_id_to_ncbi_rid[contig_id] = rid\n",
      "    time.sleep(random.randint(3, 7))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 264
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save the map from contig id to NCBI job id."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CONTIG_ID_TO_NCBI_MAP_CSV = os.path.join(VELVET_DATA_DIR, 'contig_id_to_ncbi_rid_map.csv')\n",
      "with open(CONTIG_ID_TO_NCBI_MAP_CSV, 'w') as fh:\n",
      "    for contig_id, rid in contig_id_to_ncbi_rid.iteritems():\n",
      "        fh.write(contig_id + ',' + rid + '\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 265
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we'll request results from NCBI and write to an output file. We'll grab both xml and html just in case. We write this function so that it can be run repeatedly in the case that jobs are still processing, but avoids making a repeated request for a job that we've already downloaded the data from."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(NCBIWWW)\n",
      "BLAST_XML_OUTPUT_DIR = os.path.join(VELVET_DATA_DIR, 'blast_xml')\n",
      "BLAST_HTML_OUTPUT_DIR = os.path.join(VELVET_DATA_DIR, 'blast_html')\n",
      "def write_results_to_file(contig_id, rid, xml_or_html):\n",
      "    \"\"\"Performs BLAST and saves to xml.\n",
      "    \"\"\"\n",
      "    assert xml_or_html in ['XML', 'HTML']\n",
      "    \n",
      "    type_to_ext = {'XML': '.xml', 'HTML': '.html'}\n",
      "    dest_ext = type_to_ext[xml_or_html]\n",
      "    type_to_output_dir = {'XML': BLAST_XML_OUTPUT_DIR, 'HTML': BLAST_HTML_OUTPUT_DIR}\n",
      "    output_dir = type_to_output_dir[xml_or_html]\n",
      "    dest = os.path.join(output_dir, contig_id + dest_ext)\n",
      "    \n",
      "    # Don't make request if data already exists.\n",
      "    if os.path.exists(dest):\n",
      "        print 'already done ...'\n",
      "        return False\n",
      "   \n",
      "    # Prepare and make request.\n",
      "    message = 'ALIGNMENTS=500&DESCRIPTIONS=500&FORMAT_TYPE={format_type}&RID={rid}&CMD=Get'.format(\n",
      "        format_type=xml_or_html,\n",
      "        rid=rid,\n",
      "    )\n",
      "    request = _Request(\"http://blast.ncbi.nlm.nih.gov/Blast.cgi\",\n",
      "            message, {\"User-Agent\":\"BiopythonClient\"})\n",
      "    print 'making request ...'\n",
      "    handle = _urlopen(request)\n",
      "    time.sleep(random.randint(2, 3))\n",
      "    results = _as_string(handle.read())\n",
      "    \n",
      "    # Determine whether ready.\n",
      "    is_ready = False\n",
      "    if \"Status=\" not in results:\n",
      "        is_ready = True\n",
      "    else:\n",
      "        i = results.index(\"Status=\")\n",
      "        j = results.index(\"\\n\", i)\n",
      "        status = results[i+len(\"Status=\"):j].strip()\n",
      "        if status.upper() == \"READY\":\n",
      "            is_ready = True\n",
      "        \n",
      "    # Write if rady.\n",
      "    if is_ready:\n",
      "        print 'ready, writing results ...'\n",
      "        with open(dest, 'w') as output_fh:\n",
      "            output_fh.write(results)\n",
      "    else:\n",
      "        print 'still waiting ...'\n",
      "    \n",
      "    return True\n",
      "\n",
      "count = 1\n",
      "total = len(contig_id_to_ncbi_rid)\n",
      "for contig_id, rid in contig_id_to_ncbi_rid.iteritems():\n",
      "    print '>>>>>>>>>>>>Running %d of %d' % (count, total)\n",
      "    write_results_to_file(contig_id, rid, 'XML')\n",
      "    write_results_to_file(contig_id, rid, 'HTML')\n",
      "    count += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Fix HTML Results\n",
      "\n",
      "**UPDATE:** It turns out that it's not enough to update static links to fix html files as the links to specific alignments go to a cached page (which expire after a couple days). Saving this code for posterity anyway.\n",
      "\n",
      "The HTML files have broken static links which prevent them from displaying correctly. The static links are relative rather than absolute. These can be fixed with regular expression searches."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fix_static_html():\n",
      "    for filename in os.listdir(BLAST_XML_OUTPUT_DIR):\n",
      "        if not os.path.splitext(filename)[1] == '.html':\n",
      "            continue\n",
      "        full_path = os.path.join(BLAST_XML_OUTPUT_DIR, filename)\n",
      "        new_html_path = os.path.splitext(full_path)[0] + '.mod.html'\n",
      "        with open(new_html_path, 'w') as output_fh:\n",
      "            with open(full_path) as input_fh:\n",
      "                for line in input_fh:\n",
      "                    mod_line = line\n",
      "                    if re.search(r'link rel=\"stylesheet\"', line):\n",
      "                        mod_line = line.replace('href=\"', 'href=\"http://blast.ncbi.nlm.nih.gov/')\n",
      "                    elif re.search(r'<script.*javascript.*src=\"', line):\n",
      "                        mod_line = line.replace('src=\"', 'src=\"http://blast.ncbi.nlm.nih.gov/')          \n",
      "                    elif re.search(r'img.*src=', line):\n",
      "                        mod_line = line.replace('src=\"', 'src=\"http://blast.ncbi.nlm.nih.gov/')\n",
      "                    else:\n",
      "                        mod_line = line\n",
      "                    output_fh.write(mod_line)\n",
      "# fix_static_html()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 242
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Parse xml data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Scratch"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio._py3k import StringIO\n",
      "from Bio._py3k import _as_string, _as_bytes\n",
      "from Bio._py3k import urlopen as _urlopen\n",
      "from Bio._py3k import urlencode as _urlencode\n",
      "from Bio._py3k import Request as _Request\n",
      "\n",
      "message = 'ALIGNMENTS=500&DESCRIPTIONS=500&FORMAT_TYPE=HTML&RID=WUYYKHRF014&CMD=Get'\n",
      "request = _Request(\"http://blast.ncbi.nlm.nih.gov/Blast.cgi\",\n",
      "                   message,\n",
      "                   {\"User-Agent\":\"BiopythonClient\"})\n",
      "handle = _urlopen(request)\n",
      "results = _as_string(handle.read())\n",
      "'Status=' in results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 122,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('data/test_output.html', 'w') as fh:\n",
      "    fh.write(results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seq = contig_data_df.iloc[0]['sequence']\n",
      "from Bio.Blast import NCBIWWW\n",
      "reload(NCBIWWW)\n",
      "result3 = NCBIWWW.qblast('blastn', 'nr', seq)\n",
      "print result3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<urllib2.Request instance at 0x34bc8c0>\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urlparse\n",
      "from Bio._py3k import _as_string, _as_bytes\n",
      "from Bio._py3k import urlopen as _urlopen\n",
      "request = result3\n",
      "urlparse.urljoin(result3.get_full_url(), result3.get_data())\n",
      "handle = _urlopen(request)\n",
      "results = _as_string(handle.read())\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "request = result3\n",
      "urlparse.urljoin(result3.get_full_url(), result3.get_data())\n",
      "handle = _urlopen(request)\n",
      "results = _as_string(handle.read())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"Status=\" not in results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "urlparse.urljoin(result3.get_full_url(), result3.get_data())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "'http://blast.ncbi.nlm.nih.gov/ALIGNMENTS=500&DESCRIPTIONS=500&FORMAT_TYPE=XML&RID=WUV0X2MP01R&CMD=Get'"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('data/test_ncbi_output.html', 'w') as fh:\n",
      "    fh.write(results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio.Blast import NCBIXML\n",
      "from StringIO import StringIO\n",
      "parsed = NCBIXML.parse(StringIO(results))\n",
      "x = parsed.next()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = x.alignments[0]\n",
      "a.hit_def\n",
      "a.length\n",
      "a.title\n",
      "hsps = a.hsps[0]\n",
      "hsps.query_start\n",
      "hsps.query_end\n",
      "hsps.sbjct_start\n",
      "hsps.sbjct_end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "3253"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a.title\n",
      "str(hsps)\n",
      "a.title"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 260,
       "text": [
        "u'gi|551423|emb|X81838.1| E.coli DNA for pBAD18 cloning vector'"
       ]
      }
     ],
     "prompt_number": 260
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#[a.title for a in x.alignments]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "[u'gi|46561795|gb|AY584602.1| RpL23-fusion expression vector pScFV, complete sequence',\n",
        " u'gi|46561791|gb|AY584601.1| RpL23-fusion expression vector pSA, complete sequence',\n",
        " u'gi|46561787|gb|AY584600.1| Expression vector prpL23, complete sequence',\n",
        " u'gi|46561783|gb|AY584599.1| RpL23-fusion expression vector pGFP, complete sequence',\n",
        " u'gi|46561779|gb|AY584598.1| RpL23-fusion expression vector pmIL-6, complete sequence',\n",
        " u'gi|46561775|gb|AY584597.1| RpL23-fusion expression vector pyEF1A, complete sequence',\n",
        " u'gi|124491094|gb|EF392865.1| Cloning vector pN15E4, complete sequence',\n",
        " u'gi|662247342|gb|KJ720574.1| Integrative expression vector pBD62, complete sequence',\n",
        " u'gi|526131136|gb|KF020495.1| Cloning vector pBAD24-rnc-sfGFP, complete sequence',\n",
        " u'gi|526131134|gb|KF020494.1| Cloning vector pBAD24-sfGFPx2, complete sequence',\n",
        " u'gi|526131132|gb|KF020493.1| Cloning vector pBAD24-sfGFPx1, complete sequence',\n",
        " u'gi|326650004|gb|HM241886.1| Cloning vector pBAD24-Gluc, complete sequence',\n",
        " u'gi|138754318|emb|AM403094.1| Cloning vector pSC101BADgbaA-ISceI(amp)',\n",
        " u'gi|56792955|gb|AY842513.1| Synthetic construct AraC (araC) and SecB (secB) genes, complete cds',\n",
        " u'gi|70955702|gb|DQ131584.1| Expression vector pBAD322S, complete sequence',\n",
        " u'gi|74231256|gb|DQ119287.1| Expression vector pBAD322Tp, complete sequence',\n",
        " u'gi|74231252|gb|DQ119286.1| Expression vector pBAD322T, complete sequence',\n",
        " u'gi|74231249|gb|DQ119285.1| Expression vector pBAD322K, complete sequence',\n",
        " u'gi|74231246|gb|DQ119284.1| Expression vector pBAD322G, complete sequence',\n",
        " u'gi|74231243|gb|DQ119283.1| Expression vector pBAD322C, complete sequence',\n",
        " u'gi|74231240|gb|DQ119282.1| Expression vector pBAD322, complete sequence',\n",
        " u'gi|85068490|gb|DQ266354.2| Cloning vector pBAD24hyg, complete sequence',\n",
        " u'gi|22074788|gb|AY112733.1| Broad host range vector pMLBAD, complete sequence',\n",
        " u'gi|551424|emb|X81837.1| E.coli DNA for pBAD24 cloning vector',\n",
        " u'gi|506971375|gb|JX516791.1| Plasmid vector pARAGW, complete sequence',\n",
        " u'gi|509421268|gb|JX524202.1| Plasmid vector pARAtrfA, complete sequence',\n",
        " u'gi|226344766|gb|FJ797515.1| Expression vector pBADSce, complete sequence',\n",
        " u'gi|613477947|gb|KJ170897.1| Cloning vector pACYC184-ara-xylE, complete sequence',\n",
        " u'gi|425876831|gb|JX966414.1| CipA expression vector pDGO-40, complete sequence',\n",
        " u'gi|425876826|gb|JX966413.1| Empty expression vector pDGO-37, complete sequence',\n",
        " u'gi|403182289|gb|JX239262.1| Cloning vector pGRG36pir-116-FKm, complete sequence',\n",
        " u'gi|403182281|gb|JX239261.1| Cloning vector pGRG36pir-116, complete sequence',\n",
        " u'gi|403182273|gb|JX239260.1| Cloning vector pGRG36pir, complete sequence',\n",
        " u'gi|317414275|dbj|AB598835.1| Expression plasmid pBAD-IEE DNA, complete sequence',\n",
        " u'gi|295848114|gb|HM070247.1| Expression vector pSABAD92A, complete sequence',\n",
        " u'gi|154918186|gb|EU073163.1| Shuttle vector pUCP18-RedS, complete sequence',\n",
        " u'gi|110227304|gb|DQ642043.1| Shuttle vector pMQ97, complete sequence',\n",
        " u'gi|110227298|gb|DQ642042.1| Shuttle vector pMQ95, complete sequence',\n",
        " u'gi|110227292|gb|DQ642041.1| Shuttle vector pMQ80, complete sequence',\n",
        " u'gi|110227285|gb|DQ642040.1| Shuttle vector pMQ79, complete sequence',\n",
        " u'gi|110227279|gb|DQ642039.1| Shuttle vector pMQ78, complete sequence',\n",
        " u'gi|110227268|gb|DQ642037.1| Shuttle vector pMQ72, complete sequence',\n",
        " u'gi|110227262|gb|DQ642036.1| Shuttle vector pMQ71, complete sequence',\n",
        " u'gi|110227257|gb|DQ642035.1| Shuttle vector pMQ70, complete sequence',\n",
        " u'gi|92429681|gb|DQ460223.1| Tn7 delivery vector pGRG36, complete sequence',\n",
        " u'gi|64174809|gb|DQ016036.1| Expression vector pSFBAD09, complete sequence',\n",
        " u'gi|55274265|gb|AY785150.1| Expression vector pFL190, complete sequence',\n",
        " u'gi|6003507|gb|AF179381.1|AF179381 Expression vector pJN105, complete sequence',\n",
        " u'gi|1490531|gb|U62637.1|CVU62637 Cloning vector pBAD-GFPuv, complete sequence',\n",
        " u'gi|551423|emb|X81838.1| E.coli DNA for pBAD18 cloning vector']"
       ]
      }
     ],
     "prompt_number": 71
    }
   ],
   "metadata": {}
  }
 ]
}